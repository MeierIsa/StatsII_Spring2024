demo ()
Nile
plot (Nile)
x<-c(1:10)
y <- x + 11
y <- c(x, 11)
y <- c(x, 11)
xMean <- mean(x)
xLength <- length(x)
xDevSq <- xDev^2
xSumDevSq <- sum(xDevSq)
xVar <- xSumDevSq/xLength
xSD <- sqrt(xVar)
sd(x)
xVar_s <- xSumDevSq/(xLength - 1)
search()
install.packages("tidyverse")
library("tidyverse")
search()
help(tidyverse)
example(persp)
?mtcars
summary(mtcars)
summary(mtcars)
mtcars$am <- as.factor(mtcars$am)
mtcars$cyl <- as.factor(mtcars$cyl)
ggplot(mtcars, aes(wt, mpg, size = hp)) +
geom_text(aes(size = hp, label = cyl, color = am)) +
geom_smooth(aes(linetype = cyl), color = "grey", size = 0.5, se = FALSE, show.legend = FALSE) +
guides(size = "none") +
theme_classic() +
theme(legend.title = element_blank(), legend.justification = c(1, 1), legend.position = c(1, 1)) +
scale_color_manual(labels = c("manual", "automatic"), values = c("blue", "red")) +
labs(title = "Plot of Fuel Efficiency by Weight for 32 Cars", subtitle = "Number of cylinders; size = horsepower") +
xlab("weight (1000 lbs)")
getwd()
?setwd()
?setwd()
4+4
b<-4
install.packages('IRkernel')
IRkernel::installspec(user = FALSE)
library(IRkernel)
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
expenditure <- read.table("https://raw.githubusercontent.com/ASDS-TCD/StatsI_Fall2023/main/datasets/expenditure.txt", header=T)
n <- length(y)
pdf("plot_example.pdf")
plot(expenditure$X1, expenditure$Y)
dev.off()
plot(expenditure$X1, expenditure$Y)
dev.off()
library(tidyverse)
library(stargazer)
5bdc8e1c.bf11.4f49.9272.655d42bdfde8_Series...Metadata <- read.csv("~/Desktop/Stats_Spring2024/P_Data_Extract_From_World_Development_Indicators/5bdc8e1c-bf11-4f49-9272-655d42bdfde8_Series - Metadata.csv", header=FALSE, comment.char="#")
data <- read_csv("/Users/isabellameier/Desktop/Stats_Spring2024/P_Data_Extract_From_World_Development_Indicators/5bdc8e1c-bf11-4f49-9272-655d42bdfde8_Series - Metadata.csv")
head(data)
data <- read_csv("/Users/isabellameier/Desktop/Stats_Spring2024/P_Data_Extract_From_World_Development_Indicators/5bdc8e1c-bf11-4f49-9272-655d42bdfde8_Data.csv")
head(data)
tail(data)
data <- read_csv("/Users/isabellameier/Documents/GitHub/StatsII_Spring2024/tutorials/tutorial01/tutorial1_data.csv")
head(data)
tail(data)
data['Time Code']
data['Country Name']
# 2. Let's drop the rows and columns we don't need.
# We only have one year, so the two cols related to year can be dropped; also, we only
# really need one col for country name, so let's drop country code too.
data_minus <- data[,-1]
print(data_minus)
# 2. Let's drop the rows and columns we don't need.
# We only have one year, so the two cols related to year can be dropped; also, we only
# really need one col for country name, so let's drop country code too.
data_minus <- data[,!names(data) %in% c('Time', 'Time Code', 'Country Code')]
print(data_minus)
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c(),  pkgTest)
setwd("/Users/isabellameier/Documents/GitHub/StatsII_Spring2024/problemSets/PS02answers")
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2024/blob/main/datasets/climateSupport.RData?raw=true"))
View(climateSupport)
climateSupport(head)
head(climateSupport)
#####################
# Problem 2
#####################
# Generating the data
set.seed (123)
data_2 <- data.frame(x = runif(200, 1, 10))
data_2$y <- 0 + 2.75*data_2$x + rnorm(200, 0, 1.5)
# defining the function
OLS_obj <- function(beta, x, y) {
y_esp <- beta[1] + beta[2]*x
error <- y - y_esp
return(sum(error^2))
}
# Beta values at first
beta_um <- c(0, 0)
# Optimising with BFGS
bfg_otimo <- optim(par = beta_um, fn = OLS_obj, x = data_2$x, y = data_2$y, method = "BFGS")
# getting the estimated coefficients
bfg_estcoef <- bfg_otimo$par
# Comparing the coefficients from BFGS with the lm
lm_comp <- lm(y ~ x, data = data_2)
coef_lm <- coef(lm_comp)
#
print(bfg_estcoef)
print(coef_lm)
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2024/blob/main/datasets/climateSupport.RData?raw=true"))
head(climateSupport)
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
library(mgcv)
#
climateSupport$choice <- as.numeric(climateSupport$choice == "Supported")
head(climateSupport)
#
formula <- choice ~ s(countries) + s(sanctions)
gam_model <- gam(formula, data = climateSupport)
#
class(climateSupport$countries)
class(climateSupport$sanctions)
#
sum(is.na(climateSupport))
sum(is.infinite(climateSupport))
sum(is.infinite(climateSupport$countries))
sum(is.infinite(climateSupport$sanctions))
#
sum(is.na(climateSupport$countries))
#
sum(is.na(climateSupport$sanctions))
#
formula <- choice ~ s(countries) + s(sanctions)
gam_model <- gam(formula, data = climateSupport)
summary(gam_model)
install.packages("gam")
library(gam)
#
formula <- choice ~ s(countries) + s(sanctions)
gam_model <- gam(formula, data = climateSupport)
#
formula <- choice ~ s(factor(countries)) + s(factor(sanctions))
gam_model <- gam(formula, data = climateSupport)
summary(gam_model)
#
formula <- choice ~ ns(countries, df = 3) + ns(sanctions, df = 3)
model_g <- glm(formula, data = climateSupport, family = binomial(link = "logit"))
summary(model_g)
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("yelp_data_small.csv",
stringsAsFactors=FALSE,
encoding = "utf-8")
data <- read.csv("yelp_data_small.csv",
stringsAsFactors=FALSE,
encoding = "utf-8")
---
title: 'Homework 3: supervised classification'
setwd("/Users/isabellameier/Documents/GitHub/QTA_Spring23")
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```{r}
data <- read.csv("yelp_data_small.csv",
stringsAsFactors=FALSE,
encoding = "utf-8")
getwd()
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("yelp_data_small.csv",
stringsAsFactors=FALSE,
encoding = "utf-8")
library(quanteda)
library(quanteda.textstats)
library(quanteda.textplots)
corpus <- corpus(data)
View(data)
sentiment_table <- table(corpus$sentiment)
probably_positive <- sentiment_table["pos"] / sum(sentiment_table)
print(probably_positive)
print(sentiment_table)
dfm <- dfm(data)
dfm <- dfm(corpus)
# Your code here
tokens <- tokens(corpus)
dfm <- dfm(corpus)
dfm <- dfm(tokens)
tmpdata <- as.data.frame(dfm)
tmpdata <- convert(dfm, to = 'data.frame')
tmpdata <- tmpdata[, -1]
sentiment <- as.factor(dfm$sentiment) # extract sentiment labels from the dfm object (hint: the dfm is an S4 class object)
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
lapply(c(),  pkgTest)
graduation <- read.table("http://statmath.wu.ac.at/courses/StatsWithR/Powers.txt",
stringsAsFactors = TRUE)
lapply(c("tidyverse", "car"),  pkgTest)
graduation <- read.table("http://statmath.wu.ac.at/courses/StatsWithR/Powers.txt",
stringsAsFactors = TRUE)
# 1. This time, let's analyse the data in more detail. Run some checks to see if
#    the data are well distributed. Try some simple plots to get an idea of the
#    relationship between variables. Drop those errors too.
xtabs(~ hsgrad + nonwhite, data = graduation)
with(graduation, table(hsgrad, nonwhite))
summary(graduation)
# 2. Last week we created a kitchen sink model, with nsibs as a binned factor.
#    Here was the code:
graduation$nsibs_cut <- cut(graduation$nsibs,
breaks = c(0, 0.9, 1, 3, Inf),
include.lowest = TRUE,
labels = c("None", "One", "Two_Three", "FourPlus"))
mod_1 <- glm(hsgrad ~.,
data = graduation[,!names(graduation) %in% c("nsibs")],
family = "binomial")
mod_2 <- glm(hsgrad ~ nsibs_cut + income + nonwhite,
data = graduation,
family = "binomial")
graduation[which(graduation$nsibs < 0),]
graduation <- graduation[-which(graduation$nsibs < 0),]
# 2. Last week we created a kitchen sink model, with nsibs as a binned factor.
#    Here was the code:
graduation$nsibs_cut <- cut(graduation$nsibs,
breaks = c(0, 0.9, 1, 3, Inf),
include.lowest = TRUE,
labels = c("None", "One", "Two_Three", "FourPlus"))
mod_1 <- glm(hsgrad ~.,
data = graduation[,!names(graduation) %in% c("nsibs")],
family = "binomial")
mod_2 <- glm(hsgrad ~ nsibs_cut + income + nonwhite,
data = graduation,
family = "binomial")
summary (mod_2)
# 3. a) Create a new data frame comprising the outcome variable and two columns
#       of fitted values, one from mod_1 and another from mod_2.
predicted_data <- data.frame(
hsgrad = graduation$hsgrad,
mod_1_hat = mod_1$fitted.values,
mod_2_hat = mod_2$fitted.values
)
# 3. b) Create a pipe (without reassigning) whereby you reorder your new
#       dataframe according to the fitted values of mod_1, create a new rank
#       variable, then create a scatterplot of rank by fitted value,
#       colored by the outcome variable.
predicted_data %>%
arrange(mod_1_hat) %>%
mutate(rank = row_number()) %>%
ggplot(aes(rank, mod_1_hat)) +
geom_point(aes(colour = hsgrad), alpha = 0.5) +
scale_y_continuous(limits = c(0,1))
predicted_data %>%
arrange(mod_2_hat) %>%
mutate(rank = row_number()) %>%
ggplot(aes(rank, mod_2_hat)) +
geom_point(aes(colour = hsgrad), alpha = 0.5) +
scale_y_continuous(limits = c(0,1))
# 4. Calculate McFadden's Pseudo R squared for both models.
#    Which model explains more variance?
#    What are the p values?
mod_1$null.deviance == mod_2$null.deviance
ll.null <- mod_1$null.deviance/-2
ll.fit_1 <- mod_1$deviance/-2
ll.fit_2 <- mod_2$deviance/-2
r.sq.mod_1 <- (ll.null-ll.fit_1)/ll.null
r.sq.mod_2 <- (ll.null-ll.fit_2)/ll.null
# Approach 2:
mod_null <- glm(hsgrad ~ 1, data = graduation, family = "binomial")
1 - logLik(mod_1)/logLik(mod_null)
1 - logLik(mod_2)/logLik(mod_null)
# P value:
1 - pchisq(2*(ll.fit_1 - ll.null), df = (length(mod_1$coefficients)-1))
1 - pchisq(2*(ll.fit_2 - ll.null), df = (length(mod_2$coefficients)-1))
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
library(mgcv)
lapply(c(),  pkgTest)
install.packages("gam")
install.packages("gam")
setwd("/Users/isabellameier/Documents/GitHub/StatsII_Spring2024/problemSets/PS02answers")
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2024/blob/main/datasets/climateSupport.RData?raw=true"))
head(climateSupport)
# Converting the "choice" column into 1s and 0s
climateSupport$choice <- as.numeric(climateSupport$choice == "Supported")
head(climateSupport)
#
sum(is.na(climateSupport$sanctions))
sum(is.infinite(climateSupport$sanctions))
#
formula <- choice ~ ns(countries, df = 3) + ns(sanctions, df = 3)
model_g <- glm(formula, data = climateSupport, family = binomial(link = "logit"))
View(climateSupport)
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
library(mgcv)
install.packages("gam")
library(gam)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd("/Users/isabellameier/Documents/GitHub/StatsII_Spring2024/problemSets/PS02answers")
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2024/blob/main/datasets/climateSupport.RData?raw=true"))
head(climateSupport)
# Converting the "choice" column into 1s and 0s
climateSupport$choice <- as.numeric(climateSupport$choice == "Supported")
head(climateSupport)
#
sum(is.na(climateSupport$sanctions))
sum(is.infinite(climateSupport$sanctions))
#
formula <- choice ~ ns(countries, df = 3) + ns(sanctions, df = 3)
model_g <- glm(formula, data = climateSupport, family = binomial(link = "logit"))
climateSupport$countries_num <- as.numeric(sapply(strsplit(as.character(climateSupport$countries), "of"), "[", 1))
head(climateSupport$countries_num)
#
sanctions_mapping <- c("none" = 0, "5%" = 5, "15%" = 15, "20%" = 20)
climateSupport$sanctions_num <- sanctions_mapping[climateSupport$sanctions]
head(climateSupport$sanctions_num)
#
formula <- choice ~ ns(countries_num) + ns(sanctions_num)
model_g <- glm(formula, data = climateSupport, family = binomial(link = "logit"))
summary(model_g)
View(model_g)
